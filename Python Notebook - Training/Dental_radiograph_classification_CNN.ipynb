{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import dependencies"
      ],
      "metadata": {
        "id": "3mT9wNEwm4Fl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxJk_DfA-JQL"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define the model\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzip file of xray and non-xray"
      ],
      "metadata": {
        "id": "ZZ0u9oQ5m_G1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to your zip file\n",
        "zip_file_path = '/content/non_xray.zip'\n",
        "\n",
        "# Specify the directory where you want to extract the contents\n",
        "extracted_path = '/content'\n",
        "\n",
        "# Unzip the file\n",
        "import zipfile\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_path)\n",
        "\n",
        "# Print a message indicating successful extraction\n",
        "print(f\"File '{zip_file_path}' successfully extracted to '{extracted_path}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhEjKwNhAtak",
        "outputId": "ef904f0b-c921-4710-8dd4-8ff124284a40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File '/content/non_xray.zip' successfully extracted to '/content'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train classification model"
      ],
      "metadata": {
        "id": "BVIhIAlmnC4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/dataset/training',  # Main directory containing subdirectories for each class\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary',  # Since it's a binary classification task\n",
        "\n",
        "        # Specify the classes\n",
        "        classes=['xray', 'non_xray'],\n",
        "\n",
        "        # Shuffle the data for better training\n",
        "        shuffle=True)\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "      epochs=20)\n",
        "\n",
        "# Save the model\n",
        "model.save('xray_classification_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IBTIDfuBbXk",
        "outputId": "d7f81568-d306-4cbc-db96-a211b006cc53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1018 images belonging to 2 classes.\n",
            "Epoch 1/20\n",
            " 6/31 [====>.........................] - ETA: 1:35 - loss: 2.6677 - accuracy: 0.5156"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 134s 4s/step - loss: 0.9380 - accuracy: 0.6349\n",
            "Epoch 2/20\n",
            "31/31 [==============================] - 124s 4s/step - loss: 0.3999 - accuracy: 0.7596\n",
            "Epoch 3/20\n",
            "31/31 [==============================] - 124s 4s/step - loss: 0.3781 - accuracy: 0.8590\n",
            "Epoch 4/20\n",
            "31/31 [==============================] - 120s 4s/step - loss: 0.3600 - accuracy: 0.8529\n",
            "Epoch 5/20\n",
            "31/31 [==============================] - 126s 4s/step - loss: 0.3082 - accuracy: 0.9037\n",
            "Epoch 6/20\n",
            "31/31 [==============================] - 130s 4s/step - loss: 0.2898 - accuracy: 0.9300\n",
            "Epoch 7/20\n",
            "31/31 [==============================] - 120s 4s/step - loss: 0.2717 - accuracy: 0.9493\n",
            "Epoch 8/20\n",
            "31/31 [==============================] - 122s 4s/step - loss: 0.2585 - accuracy: 0.9564\n",
            "Epoch 9/20\n",
            "31/31 [==============================] - 123s 4s/step - loss: 0.2562 - accuracy: 0.9584\n",
            "Epoch 10/20\n",
            "31/31 [==============================] - 132s 4s/step - loss: 0.2301 - accuracy: 0.9757\n",
            "Epoch 11/20\n",
            "31/31 [==============================] - 120s 4s/step - loss: 0.1975 - accuracy: 0.9777\n",
            "Epoch 12/20\n",
            "31/31 [==============================] - 121s 4s/step - loss: 0.1279 - accuracy: 0.9564\n",
            "Epoch 13/20\n",
            "31/31 [==============================] - 121s 4s/step - loss: 0.0701 - accuracy: 0.9746\n",
            "Epoch 14/20\n",
            "31/31 [==============================] - 120s 4s/step - loss: 0.0533 - accuracy: 0.9828\n",
            "Epoch 15/20\n",
            "31/31 [==============================] - 127s 4s/step - loss: 0.0966 - accuracy: 0.9767\n",
            "Epoch 16/20\n",
            "31/31 [==============================] - 122s 4s/step - loss: 0.1720 - accuracy: 0.9331\n",
            "Epoch 17/20\n",
            "31/31 [==============================] - 120s 4s/step - loss: 0.1026 - accuracy: 0.9667\n",
            "Epoch 18/20\n",
            "31/31 [==============================] - 120s 4s/step - loss: 0.0816 - accuracy: 0.9655\n",
            "Epoch 19/20\n",
            "31/31 [==============================] - 130s 4s/step - loss: 0.0362 - accuracy: 0.9899\n",
            "Epoch 20/20\n",
            "31/31 [==============================] - 120s 4s/step - loss: 0.0413 - accuracy: 0.9817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload image and test the model"
      ],
      "metadata": {
        "id": "eESVNIGanGd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('/content/compressed.h5')\n",
        "\n",
        "# Upload an image from your device\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the uploaded image\n",
        "uploaded_file_path = list(uploaded.keys())[0]\n",
        "img = image.load_img(io.BytesIO(uploaded[uploaded_file_path]), target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.0  # Rescale the pixel values to the range [0, 1]\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(img_array)\n",
        "print(predictions)\n",
        "\n",
        "# Interpret the predictions\n",
        "if predictions[0, 0] < 0.5:\n",
        "    print(\"Prediction: X-ray\")\n",
        "else:\n",
        "    print(\"Prediction: Non-X-ray\")\n"
      ],
      "metadata": {
        "id": "9aZ5bYmcBbee"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}